{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SilverSurferClash/Regression_templates/blob/main/feb_2021_nn_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3RADG32dJeK",
        "outputId": "15114b8c-23bf-4775-b827-60f588b20812"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nEFxRKwyrrV",
        "outputId": "529ac537-7d10-4b2d-bc35-6c578c200835"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 924 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.12.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.5.1.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "#Import os libaries\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "#Import data manipulation libaries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "#import ploting libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Splitting the data and cross-validation\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, cross_val_score,KFold, GroupKFold, StratifiedKFold\n",
        "\n",
        "#Metrics\n",
        "#from sklearn.metrics import classification_report,accuracy_score , roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#Classifiers\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "#from catboost import CatBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "\n",
        "#Feature engineerring\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "\n",
        "#Encoding\n",
        "\n",
        "import category_encoders as ce\n",
        "\n",
        "#Helper modules\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-12-15T08:27:14.897202Z",
          "iopub.execute_input": "2022-12-15T08:27:14.897563Z",
          "iopub.status.idle": "2022-12-15T08:27:14.906688Z",
          "shell.execute_reply.started": "2022-12-15T08:27:14.897533Z",
          "shell.execute_reply": "2022-12-15T08:27:14.905293Z"
        },
        "trusted": true,
        "id": "16ZkVC_FdGpT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Notebook settings\n",
        "# To define maximum number of columns to be displayed in a dataframe\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# To supress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Set the theme for seaborn\n",
        "#sns.set_theme(style=\"darkgrid\")\n",
        "pd.set_option('display.precision', 2)\n",
        "\n",
        "#Set dark theme\n",
        "plt.style.use('dark_background')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-15T08:27:14.909032Z",
          "iopub.execute_input": "2022-12-15T08:27:14.909810Z",
          "iopub.status.idle": "2022-12-15T08:27:14.924082Z",
          "shell.execute_reply.started": "2022-12-15T08:27:14.909735Z",
          "shell.execute_reply": "2022-12-15T08:27:14.922905Z"
        },
        "trusted": true,
        "id": "pT5-qiUOdGpV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jA4QoWY2do4m",
        "outputId": "2ed3c8e7-c17e-48f6-b985-b24c2d3b984a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Colab_Notebooks/deep_learning\")"
      ],
      "metadata": {
        "id": "wZpE-ihje7Au"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_import = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "WHBFhcq3gUVC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### List of different feature sets"
      ],
      "metadata": {
        "id": "4m_-tvq5dGpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of colums based on their function\n",
        "# Target\n",
        "target_label  = \"target\"\n",
        "# List of all features\n",
        "all_feature = [col for col in train_import.columns if col != \"target\"]\n",
        "# List of numeric features\n",
        "all_numeric = [col for col in all_feature if train_import[col].dtype == \"float64\"]\n",
        "# List of all categorical features\n",
        "all_categorical = [col for col in all_feature if train_import[col].dtype == \"object\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-15T08:27:16.427630Z",
          "iopub.execute_input": "2022-12-15T08:27:16.428099Z",
          "iopub.status.idle": "2022-12-15T08:27:16.436192Z",
          "shell.execute_reply.started": "2022-12-15T08:27:16.428063Z",
          "shell.execute_reply": "2022-12-15T08:27:16.435205Z"
        },
        "trusted": true,
        "id": "JWYDBhsNdGpX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 0: Drop non-essential columns\n",
        "#Step 1: Perform imputation or encoding of missing data\n",
        "#Step 2: Perform encoding for the different categorical columns\n",
        "#Step 3: feature transformation of numeric features\n",
        "#Step 4: feature generation by aggregation/groupby function\n",
        "#Step 5: "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-15T08:27:16.437750Z",
          "iopub.execute_input": "2022-12-15T08:27:16.438509Z",
          "iopub.status.idle": "2022-12-15T08:27:16.449254Z",
          "shell.execute_reply.started": "2022-12-15T08:27:16.438475Z",
          "shell.execute_reply": "2022-12-15T08:27:16.448302Z"
        },
        "trusted": true,
        "id": "TTTen8HHdGpX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the feature matrix and target values"
      ],
      "metadata": {
        "id": "Tk18DlFrdGpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the training feature matrix, the training feature labels and the same for the\n",
        "#validation set\n",
        "\n",
        "train = train_import.sample(frac = 0.05).copy()\n",
        "train_X = train.loc[:, all_feature]\n",
        "train_y = train.loc[:, [target_label]].values\n",
        "train_X.shape, train_y.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-15T08:27:16.451725Z",
          "iopub.execute_input": "2022-12-15T08:27:16.452835Z",
          "iopub.status.idle": "2022-12-15T08:27:16.492085Z",
          "shell.execute_reply.started": "2022-12-15T08:27:16.452807Z",
          "shell.execute_reply": "2022-12-15T08:27:16.491199Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2IFz8KfdGpY",
        "outputId": "d1d2e234-d2bd-44a9-bf82-0b4b4765effd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15000, 25), (15000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering - Encoding and Scaling"
      ],
      "metadata": {
        "id": "sS_iyO8DdGpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_continuous = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "preprocess_categorical = Pipeline(steps=[('encoder',\n",
        "ce.OneHotEncoder(cols=all_categorical))])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-15T08:27:16.493836Z",
          "iopub.execute_input": "2022-12-15T08:27:16.494386Z",
          "iopub.status.idle": "2022-12-15T08:27:16.499460Z",
          "shell.execute_reply.started": "2022-12-15T08:27:16.494352Z",
          "shell.execute_reply": "2022-12-15T08:27:16.498461Z"
        },
        "trusted": true,
        "id": "mzptqdScdGpY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer(\n",
        "transformers=[('continuous', #A\n",
        "preprocess_continuous, all_numeric),\n",
        "('categorical', #B\n",
        "preprocess_categorical, all_categorical)],\n",
        "remainder='passthrough')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-15T08:27:16.500946Z",
          "iopub.execute_input": "2022-12-15T08:27:16.501383Z",
          "iopub.status.idle": "2022-12-15T08:27:16.508904Z",
          "shell.execute_reply.started": "2022-12-15T08:27:16.501347Z",
          "shell.execute_reply": "2022-12-15T08:27:16.508023Z"
        },
        "trusted": true,
        "id": "0zV6761OdGpZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X_trans = ct.fit_transform(train_X, train_y)\n",
        "test_trans = ct.transform(test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-15T08:27:16.512144Z",
          "iopub.execute_input": "2022-12-15T08:27:16.512499Z",
          "iopub.status.idle": "2022-12-15T08:27:17.655951Z",
          "shell.execute_reply.started": "2022-12-15T08:27:16.512469Z",
          "shell.execute_reply": "2022-12-15T08:27:17.654857Z"
        },
        "trusted": true,
        "id": "fr_m7aEwdGpZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_X_trans.copy()\n",
        "train_targets = train_y.copy()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-15T08:27:17.658902Z",
          "iopub.execute_input": "2022-12-15T08:27:17.659210Z",
          "iopub.status.idle": "2022-12-15T08:27:17.666082Z",
          "shell.execute_reply.started": "2022-12-15T08:27:17.659183Z",
          "shell.execute_reply": "2022-12-15T08:27:17.665043Z"
        },
        "trusted": true,
        "id": "Uq6EFY6fdGpZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data), type(train_targets), train_targets.shape, train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJycighgTPAa",
        "outputId": "66c50c5f-8f00-4e66-c4e5-88d6eb394c2d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, numpy.ndarray, (15000, 1), (15000, 68))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Neural network"
      ],
      "metadata": {
        "id": "OI5aUe9zdGpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "aVrT3uOwV-pa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "# define the model\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "  model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "fbu3n065WA61"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model - we need a:\n",
        "#loss function\n",
        "#optimizer\n",
        "# evaluation metric\n",
        "\n",
        "#model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])"
      ],
      "metadata": {
        "id": "eFQ4KMAPXgm2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of epochs for training\n",
        "num_epochs = 5"
      ],
      "metadata": {
        "id": "yZwN-a64XYTF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build_model().fit(train_data,train_targets,\n",
        "             # epochs=num_epochs, batch_size=16, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggRDLurtjTM0",
        "outputId": "749a7f00-c28a-4eb3-aa04-b50f45a0ce19"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 4421246.0000 - mae: 956.1060\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 1s 2ms/step - loss: 875022.1875 - mae: 500.8616\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 211172.4688 - mae: 277.4656\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 1s 2ms/step - loss: 21458.2578 - mae: 62.8584\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 1s 2ms/step - loss: 100.3504 - mae: 3.6847\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f22a6dd3c70>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores = []"
      ],
      "metadata": {
        "id": "7f2OUNbpj-ID"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  # Take the i fold for the validation data - shift everything by i+1\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate(\n",
        "  [train_data[:i * num_val_samples],\n",
        "  train_data[(i + 1) * num_val_samples:]],\n",
        "  axis=0)\n",
        "  partial_train_targets = np.concatenate(\n",
        "  [train_targets[:i * num_val_samples],\n",
        "  train_targets[(i + 1) * num_val_samples:]],\n",
        "  axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsf69nOekiHE",
        "outputId": "264aabd0-1bdd-4eba-c1e1-7006a23f19ee"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ]
        }
      ]
    }
  ]
}